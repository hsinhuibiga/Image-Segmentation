{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v54zGx0OD25B"
   },
   "source": [
    "the work apply the Generative Adversarial Network, GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5p4cWaLDzOX"
   },
   "outputs": [],
   "source": [
    "#We will download the database from https. \n",
    "#MAC computers need to add the following two lines so that the other partyâ€™s ssl certificate will not be considered invalid\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aSqyWHInf0TI"
   },
   "source": [
    "Import library.\n",
    "\n",
    "1.This random module implements pseudo-random number generators for various distributions.\n",
    "\n",
    "2.Using the Torchvision resource library, we can quickly use common datasets that do not need to be processed by ourselves, use the convenient and effective image transform function to process our dataset, and use the pre-trained good model\n",
    "\n",
    "3.PIL is Python image library. It consists of many different modules and provides many processing functions, allowing us to process images in a simple Python program. Using a library package like PIL allows us to focus on the image processing itself and avoid getting lost in the underlying algorithms.\n",
    "\n",
    "4.matplotlib is visualization kit for Python; torch converts the model to Torch Script;the os module provides a very rich method to handle files and directories;numpy has functions for working in domain of linear algebra, fourier transform, and matrices; cv2 provides the basic image manipulation functions.\n",
    "\n",
    "5.Load all downloader files in the current directory as modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xwu2LfNgFyr0"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from downloader import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NuQ0O7kOGh7_"
   },
   "outputs": [],
   "source": [
    "#import Generator\n",
    "from model import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3O3oBqG5GuxO"
   },
   "outputs": [],
   "source": [
    "#Use CelebA dataset\n",
    "dataset ='CelebA'\n",
    "#set the photo size as 256 \n",
    "image_size =256\n",
    "#CelebA's selected attritubes\n",
    "selected_attrs =['Gray_Hair', 'Wavy_Hair', 'Pale_Skin', 'Narrow_Eyes', 'Oval_Face']\n",
    "# select 5 dimensions \n",
    "c_dim =5\n",
    "#choose the directories\n",
    "celeba_image_dir ='data/custom/images'\n",
    "model_save_dir ='stargan_celeba_256/models'\n",
    "# The path to download the G weights file.\n",
    "G_url = 'https://github.com/hanyoseob/pytorch-StarGAN'\n",
    "# Number of conv filters in the first layer of G.\n",
    "g_conv_dim = 64\n",
    "# number of residual blocks in G\n",
    "g_repeat_num = 6\n",
    "# test model at the stage\n",
    "test_iters = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a0Lx4M3RG34x"
   },
   "outputs": [],
   "source": [
    "# increase the speed of deep learning operations\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I-X66C5Fq-Ak"
   },
   "source": [
    "GAN trains two neural networks at the same time, the generator (Generator, G) and the discriminator (Discriminator, D), which are stronger and stronger against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wGC52ZUpG9HJ"
   },
   "outputs": [],
   "source": [
    "#Generator\n",
    "G = Generator(g_conv_dim, c_dim, g_repeat_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "obA72L6CHDUv"
   },
   "outputs": [],
   "source": [
    "#network information\n",
    "def print_network(model, name):\n",
    "    num_params = 0\n",
    "    for p in model.parameters():\n",
    "        num_params += p.numel()\n",
    "    print(model)\n",
    "    print(name)\n",
    "    print(\"The number of parameters: {}\".format(num_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XJOjMAhnHKiW"
   },
   "outputs": [],
   "source": [
    "print_network(G, 'G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kd4lgMwsHVXd"
   },
   "outputs": [],
   "source": [
    "G.to(device)\n",
    "print('Models moved to', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vETgK4lMHYq3"
   },
   "outputs": [],
   "source": [
    "#resume training from this step\n",
    "resume_iters = test_iters\n",
    "print('Loading the trained models from step {}...'.format(resume_iters))\n",
    "#generator path\n",
    "G_path = os.path.join(model_save_dir, '{}-G.ckpt'.format(resume_iters))\n",
    "download_if_not_exists(G_path, G_url)\n",
    "# D_path = os.path.join(model_save_dir, '{}-D.ckpt'.format(resume_iters))\n",
    "G.load_state_dict(torch.load(G_path, map_location=lambda storage, loc: storage))\n",
    "# D.load_state_dict(torch.load(D_path, map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rnZy8xc1HlL_"
   },
   "outputs": [],
   "source": [
    "#the directory of case path\n",
    "CASE_PATH = 'data/custom/haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(CASE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VA-TERXlwduF"
   },
   "source": [
    "crop-face function, set the margin and image size as celebA as 256\n",
    "\n",
    "    :param imgarray: full image\n",
    "    :param section: face detected area (x, y, w, h)\n",
    "    :param margin: add some margin to the face detected area to include a full head\n",
    "    :param size: the result image resolution with be (size x size)\n",
    "    :return: resized image in numpy array with shape (size x size x 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R9zXE60cHrPO"
   },
   "outputs": [],
   "source": [
    "def crop_face(imgarray, section, margin=20, size=256):\n",
    "    img_h, img_w, _ = imgarray.shape\n",
    "    if section is None:\n",
    "        section = [0, 0, img_w, img_h]\n",
    "    (x, y, w, h) = section\n",
    "    margin = int(min(w, h) * margin / 100)\n",
    "    x_a = x - margin\n",
    "    y_a = y - margin\n",
    "    x_b = x + w + margin\n",
    "    y_b = y + h + margin\n",
    "    if x_a < 0:\n",
    "        x_b = min(x_b - x_a, img_w - 1)\n",
    "        x_a = 0\n",
    "    if y_a < 0:\n",
    "        y_b = min(y_b - y_a, img_h - 1)\n",
    "        y_a = 0\n",
    "    if x_b > img_w:\n",
    "        x_a = max(x_a - (x_b - img_w), 0)\n",
    "        x_b = img_w\n",
    "    if y_b > img_h:\n",
    "        y_a = max(y_a - (y_b - img_h), 0)\n",
    "        y_b = img_h\n",
    "    cropped = imgarray[y_a: y_b, x_a: x_b]\n",
    "    resized_img = cv2.resize(cropped, (size, size), interpolation=cv2.INTER_AREA)\n",
    "    resized_img = np.array(resized_img)\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lqvWQOpiH1w3"
   },
   "outputs": [],
   "source": [
    "def tryCvStarGAN(imgFile, setHairColor = 'Gray', setNarrow_Eyes = False, setOval_Face = True):\n",
    "    frame = cv2.imread(imgFile)\n",
    "    frame = frame[:, :, ::-1] # CV2'BGR -> RGB\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.2,\n",
    "        minNeighbors=10\n",
    "    )\n",
    "    if len(faces) is 0:\n",
    "        print('No face detected, try another image.')\n",
    "        return\n",
    "    main_face = max(faces, key=lambda rectangle: (rectangle[2] * rectangle[3]))  # area = w * h\n",
    "    face_img = crop_face(frame, main_face, margin = 40, size=256)\n",
    "    image = Image.fromarray(face_img)\n",
    "    \n",
    "    # Pre-process the image\n",
    "    transform = []\n",
    "    transform.append(T.ToTensor())\n",
    "    transform.append(T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)))\n",
    "    transform = T.Compose(transform)\n",
    "\n",
    "    preprocessed_image = transform(face_img)\n",
    "    \n",
    "    # See the pre-processed source image.\n",
    "    # Set the plot\n",
    "    fig=plt.figure(figsize=(8, 8))\n",
    "    columns = 2\n",
    "    rows = 1\n",
    "    fig.add_subplot(rows, columns, 1)\n",
    "    plt.imshow((np.moveaxis(preprocessed_image.numpy(),[0], [2])+1)/2)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # Pre-process the image\n",
    "    \n",
    "    \n",
    "    # Three hair color to choose from.\n",
    "    hairColors = ['Black_Hair', 'Blond_Hair', 'Brown_Hair']\n",
    "    labels = torch.zeros(c_dim)\n",
    "    # Match the user set hair color and set the label value.\n",
    "    for i, color in enumerate(hairColors):\n",
    "        if setHairColor.lower() in color.lower():\n",
    "            labels[i] = 1\n",
    "            break\n",
    "    # Set the 'Narrow_Eyes' label.\n",
    "    if setNarrow_Eyes is True:\n",
    "        labels[3] = 1\n",
    "    # Set the 'Oval_Face' label.\n",
    "    if setOval_Face is True:\n",
    "        labels[4] = 1\n",
    "    # the generator to generate the image with labels that choosed.\n",
    "    generated = G(preprocessed_image.unsqueeze(0).to(device), labels.unsqueeze(0).to(device))\n",
    "    \n",
    "    # use matplotlib to see the image from generator.\n",
    "    fig.add_subplot(rows, columns, 2)\n",
    "    plt.imshow((np.moveaxis(generated.cpu().detach().numpy()[0],[0], [2])+1)/2)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HksPgnNLIAOc"
   },
   "outputs": [],
   "source": [
    "tryCvStarGAN('data/custom/images/000016.jpg', setHairColor = 'brown', setNarrow_Eyes = False, setOval_Face = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wikBlXlpIGS4"
   },
   "outputs": [],
   "source": [
    "tryCvStarGAN('data/custom/images/000016.jpg', setHairColor = 'blond', setNarrow_Eyes = False, setOval_Face = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rZn5sZZhINCT"
   },
   "outputs": [],
   "source": [
    "t2 = torch.ones(2)\n",
    "t2.numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZzgd3guIS9Q"
   },
   "outputs": [],
   "source": [
    "torch.ones(2).numpy"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "star03.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
